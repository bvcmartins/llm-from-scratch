{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e12564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c99c3d",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753323c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50527, \n",
    "    \"context_length\": 1024, \n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251e3bc",
   "metadata": {},
   "source": [
    "### Dummy Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0543933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d9ca7",
   "metadata": {},
   "source": [
    "### Dummy GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58baf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2745856",
   "metadata": {},
   "source": [
    "### Tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfec6446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 1745,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken \n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day hold a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99cee46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouptut Shape: torch.Size([2, 4, 50527])\n",
      "tensor([[[-0.4811,  0.4325, -0.6385,  ..., -0.9398, -0.1178,  0.1945],\n",
      "         [-0.0843,  0.4519,  0.2060,  ..., -0.5766, -0.5318, -1.4576],\n",
      "         [ 0.7199,  0.0575,  0.2597,  ..., -1.0028, -1.9158, -0.5157],\n",
      "         [ 1.8422,  0.0252,  0.9573,  ..., -0.0315, -0.2424, -0.2487]],\n",
      "\n",
      "        [[-0.9559,  1.3580, -0.4468,  ..., -0.5588,  0.4615, -0.3940],\n",
      "         [-0.5088,  0.2881,  0.5815,  ..., -0.0353,  0.1133, -0.5654],\n",
      "         [-1.1309, -0.8578,  1.3953,  ...,  1.0018, -0.7334,  0.3572],\n",
      "         [ 0.6819, -0.8203,  1.2607,  ...,  1.1441, -0.7271, -2.8555]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(f\"Ouptut Shape: {logits.shape}\")\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e0cc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfd84c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>), Variance: tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(f'Mean: {mean}, Variance: {var}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d499d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs: \n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean: \n",
      " tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance: \n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(f\"Normalized layer outputs: \\n {out_norm}\")\n",
    "print(f\"Mean: \\n {mean}\")\n",
    "print(f\"Variance: \\n {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bc88ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c236258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Var: tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Var: {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df6429",
   "metadata": {},
   "source": [
    "### GELU Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4d3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x,3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "505083cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu = gelu(x)\n",
    "y_relu = relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function \")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label} \")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1a141",
   "metadata": {},
   "source": [
    "### FF Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6353b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e7d4f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([2, 3, 768])\n",
      "Output: \n",
      " tensor([[[ 0.1238,  0.0457,  0.0939,  ...,  0.1107,  0.0167, -0.1992],\n",
      "         [ 0.1574, -0.0282,  0.0049,  ...,  0.0026,  0.1120, -0.1075],\n",
      "         [ 0.1184, -0.0052,  0.0839,  ...,  0.1662,  0.0112, -0.1685]],\n",
      "\n",
      "        [[ 0.1302,  0.0630,  0.1050,  ...,  0.1439,  0.0562, -0.1128],\n",
      "         [ 0.1249, -0.0073,  0.1022,  ...,  0.0417,  0.0381, -0.0828],\n",
      "         [ 0.0494,  0.0654,  0.0347,  ...,  0.0701,  0.0793, -0.1810]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(cfg=GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768)\n",
    "out_ffn = ffn(x)\n",
    "print(f\"Output Shape: {out_ffn.shape}\")\n",
    "print(f\"Output: \\n {out_ffn}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca91dd",
   "metadata": {},
   "source": [
    "### Shortcut connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874ada7",
   "metadata": {},
   "source": [
    "#### Illustration of shortcut connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21221d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut=False):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers: \n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape: \n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6599bda",
   "metadata": {},
   "source": [
    "### Shortcut connection analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f9e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)\n",
    "\n",
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([0.])\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    loss.backward()\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name: \n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3655f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
      "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
      "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
      "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmartins/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/bmartins/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/torch/autograd/graph.py:841: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1143c2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694105327129364\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "# Testing a model with skip connections \n",
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b7aa74",
   "metadata": {},
   "source": [
    "### Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6b2dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0) # d_out must be divisible by num_heads \n",
    "        self.d_out = d_out \n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = d_out // num_heads \n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a num_heads dimension\n",
    "        # then we unroll the last dim\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose from (batch, num_tokens, num_heads, head_dim) to (batch, num_hedas, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute dot product for eqch head \n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        # masks truncated to the number of tokens - set by the longest sentence in the batch\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        # uses the mask to fill attention scores \n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        # converting to (batch, num_tokens, n_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "        # combines heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        # optional linear projection \n",
    "        context_vec = self.out_proj(context_vec)      \n",
    "        return context_vec \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1c228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "911cc1e8",
   "metadata": {},
   "source": [
    "### Transformer blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f91e65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"], \n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"], \n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54d9da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcc0f0",
   "metadata": {},
   "source": [
    "### GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "490dc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds \n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76a2dbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch: tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 1745,  257]])\n",
      "Output shape: torch.Size([2, 4, 50527])\n",
      "tensor([[[-0.4080,  1.2829,  0.1245,  ..., -0.1089,  0.3501,  1.3657],\n",
      "         [-0.2078,  0.2583,  0.5438,  ..., -0.2828, -0.6319,  0.0631],\n",
      "         [-0.9061, -0.0543, -0.3181,  ..., -0.5065, -0.7807,  0.1212],\n",
      "         [-0.0197,  0.0990, -0.2749,  ..., -0.2600, -0.7665,  0.1369]],\n",
      "\n",
      "        [[-0.8632,  1.1687, -0.1051,  ..., -0.1885,  0.2798,  1.1261],\n",
      "         [-0.0049,  1.0500, -0.4110,  ..., -0.4031, -0.4179,  0.8799],\n",
      "         [-0.6840,  0.8434,  0.1022,  ...,  0.5138,  0.5619,  0.9435],\n",
      "         [ 0.4301,  0.2137, -0.6258,  ...,  0.4201, -0.3677,  0.5656]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(f\"Input batch: {batch}\")\n",
    "print(f\"Output shape: {out.shape}\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e12b2072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,424,256\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b9dd8",
   "metadata": {},
   "source": [
    "### Weight Tying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b614cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50527, 768])\n",
      "Output layer shape: torch.Size([50527, 768])\n"
     ]
    }
   ],
   "source": [
    "print(f'Token embedding layer shape: {model.tok_emb.weight.shape}')\n",
    "print(f'Output layer shape: {model.out_head.weight.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2c33a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training parameters considering weight tying: 124619520\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = (\n",
    "    total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    ")\n",
    "print(f\"Number of training parameters considering weight tying: {total_params_gpt2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc1657",
   "metadata": {},
   "source": [
    "### Memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a04d2797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 623.41 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 # assuming float32 - 4 bytes per parameter \n",
    "total_size_mb = total_size_bytes / (1024 * 1024) # converts to MB\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d93e6",
   "metadata": {},
   "source": [
    "Output tensor: [batch_size, num_tokens, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ec1d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:] #always keep the last context_size tokens \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :] #always take the last token \n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b12c209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded:  [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded: \", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1a34b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[15496,    11,   314,   716,  5631, 32744, 22400, 49690, 33426, 15386]])\n",
      "Output length:  10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output: \", out)\n",
    "print(\"Output length: \", len(out[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78a25e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text:  Hello, I amDA REALochond assailantsahn\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(\"Decoded text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b396651",
   "metadata": {},
   "source": [
    "### Pre-training on labeled data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d353c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50527, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50527, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50527,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f9c44",
   "metadata": {},
   "source": [
    "### Test token generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64d62097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: Every effort moves you551 Scriptures transient shelterperfect oil Mist invaded Gingrichctx\n"
     ]
    }
   ],
   "source": [
    "import tiktoken \n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension \n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension \n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(f\"Output text: {token_ids_to_text(token_ids, tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8972b0",
   "metadata": {},
   "source": [
    "### Calculating text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40daa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50527])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], [40, 1107, 588]])\n",
    "targets = torch.tensor([[3626, 6100, 345], [1107, 588, 11311]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af1d78a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ids: tensor([[[23575],\n",
      "         [47550],\n",
      "         [ 5095]],\n",
      "\n",
      "        [[37094],\n",
      "         [16219],\n",
      "         [39474]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(f'Token ids: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c562c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Session STA injury\n"
     ]
    }
   ],
   "source": [
    "print(f'Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}')\n",
    "print(f'Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6f72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
