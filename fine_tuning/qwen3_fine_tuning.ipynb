{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4db8944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmartins/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.43 GiB of which 6.06 MiB is free. Process 671198 has 22.04 GiB memory in use. Including non-PyTorch memory, this process has 1.36 GiB memory in use. Of the allocated memory 1.11 GiB is allocated by PyTorch, and 4.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen3-0.6B\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Ensure pad token is set (important for batch training)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/transformers/modeling_utils.py:5048\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5038\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5039\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5041\u001b[39m     (\n\u001b[32m   5042\u001b[39m         model,\n\u001b[32m   5043\u001b[39m         missing_keys,\n\u001b[32m   5044\u001b[39m         unexpected_keys,\n\u001b[32m   5045\u001b[39m         mismatched_keys,\n\u001b[32m   5046\u001b[39m         offload_index,\n\u001b[32m   5047\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5048\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5049\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5054\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5059\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5063\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5064\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5065\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/transformers/modeling_utils.py:5468\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5465\u001b[39m         args_list = logging.tqdm(args_list, desc=\u001b[33m\"\u001b[39m\u001b[33mLoading checkpoint shards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5467\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[32m-> \u001b[39m\u001b[32m5468\u001b[39m         _error_msgs, disk_offload_index = \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5469\u001b[39m         error_msgs += _error_msgs\n\u001b[32m   5471\u001b[39m \u001b[38;5;66;03m# Save offloaded index if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/transformers/modeling_utils.py:843\u001b[39m, in \u001b[36mload_shard_file\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     disk_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/llm-scratch/lib/python3.11/site-packages/transformers/modeling_utils.py:770\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, hf_quantizer, keep_in_fp32_regex, device_mesh)\u001b[39m\n\u001b[32m    767\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled():\n\u001b[32m    768\u001b[39m         param_device = \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     _load_parameter_into_model(model, param_name, \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    773\u001b[39m     \u001b[38;5;66;03m# TODO naming is stupid it loads it as well\u001b[39;00m\n\u001b[32m    774\u001b[39m     hf_quantizer.create_quantized_param(model, param, param_name, param_device)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.43 GiB of which 6.06 MiB is free. Process 671198 has 22.04 GiB memory in use. Including non-PyTorch memory, this process has 1.36 GiB memory in use. Of the allocated memory 1.11 GiB is allocated by PyTorch, and 4.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"cuda\")\n",
    "\n",
    "# Ensure pad token is set (important for batch training)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507de36",
   "metadata": {},
   "source": [
    "### Testing the base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45196535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt text is <|im_start|>user\n",
      "how are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "\n",
      "model output: \n",
      " Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "content = \"how are you?\"\n",
    "messages = [{\"role\": \"user\", \"content\": content}]\n",
    "prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "print(f\"prompt text is {prompt_text}\")\n",
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "output_ids = model.generate(**inputs, max_new_tokens=50)\n",
    "baseline_answer = tokenizer.decode(output_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "print(f\"model output: \\n {baseline_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e6e7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff1f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([151644,    872,    198,   5158,    525,    498,     30, 151645,    198,\n",
       "        151644,  77091,    198, 151667,    271, 151668,    271,   9707,      0,\n",
       "          2585,    646,    358,   1492,    498,   3351,     30, 151645],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f795ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  9707,      0,   2585,    646,    358,   1492,    498,   3351,     30,\n",
       "        151645], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids[0][inputs['input_ids'].shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75691e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa19f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_id     sub        repr(txt) \n",
      "9707       Hello      'Hello'   \n",
      "0          !          '!'       \n",
      "2585       ĠHow       ' How'    \n",
      "646        Ġcan       ' can'    \n",
      "358        ĠI         ' I'      \n",
      "1492       Ġhelp      ' help'   \n",
      "498        Ġyou       ' you'    \n",
      "3351       Ġtoday     ' today'  \n",
      "30         ?          '?'       \n",
      "151645     <|im_end|> '<|im_end|>'\n"
     ]
    }
   ],
   "source": [
    "prompt_len = inputs['input_ids'].shape[1]\n",
    "print(\"{:<10}\".format(\"tok_id\"), \"{:<10}\".format(\"sub\"), \"{:<10}\".format(\"repr(txt)\"))\n",
    "\n",
    "gen_ids = output_ids[0, prompt_len:]\n",
    "for tok_id in gen_ids.tolist():\n",
    "    sub = tokenizer.convert_ids_to_tokens(tok_id)\n",
    "    txt = tokenizer.decode([tok_id], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "    print(\"{:<10}\".format(tok_id), \"{:<10}\".format(sub), \"{:<10}\".format(repr(txt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bd1e3",
   "metadata": {},
   "source": [
    "### Test the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP THIS CELL - it overwrites the instruction-tuned model with the base model\n",
    "# The base model is not designed for instruction following\n",
    "\n",
    "# model_name = \"Qwen/Qwen3-0.6B-Base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d2d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt text is: <|im_start|>user\n",
      "How are you<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models output: Hello! I'm a language model, and I'm here to help with anything you need! What can I do for you?\n"
     ]
    }
   ],
   "source": [
    "content = \"How are you\"\n",
    "messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "print(\"prompt text is: %s\" % prompt_text)\n",
    "\n",
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "# Generate a response\n",
    "output_ids = model.generate(**inputs, max_new_tokens=50)\n",
    "baseline_answer = tokenizer.decode(output_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "print(\"models output: %s\" % baseline_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a274a91",
   "metadata": {},
   "source": [
    "### Preparing the fine tuning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c2efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 52002/52002 [00:00<00:00, 453892.62 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 12409.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import torch \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Add download_mode to force fresh download and avoid cache issues\n",
    "raw_ds = load_dataset(\"tatsu-lab/alpaca\", split=\"train[:2000]\", download_mode=\"force_redownload\")\n",
    "\n",
    "def format_example(example):\n",
    "    if example['input']:\n",
    "        user_text = f\"{example['instruction']}\\n{example['input']}\"\n",
    "    else:\n",
    "        user_text = example['instruction']\n",
    "    prompt = (\n",
    "        f\"<[im_start]>user\\n{user_text}<[im_end]>\\n\"\n",
    "        f\"<[im_start]>assistant\\n\"\n",
    "    )\n",
    "    full_text = prompt + example[\"output\"] + \"<[im_end]>\"\n",
    "    prompt_len = len(tokenizer(prompt)[\"input_ids\"])\n",
    "    return {\"prompt\": prompt, \"full_text\": full_text, \"prompt_len\": prompt_len}\n",
    "\n",
    "chat_ds = raw_ds.map(format_example, remove_columns=raw_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'full_text', 'prompt_len'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(ex):\n",
    "    tok = tokenizer(ex[\"full_text\"], truncation=True)\n",
    "    tok[\"prompt_len\"] = ex[\"prompt_len\"]\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337f44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  40%|████      | 802/2000 [00:00<00:00, 7995.19 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 7550.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tok_ds = chat_ds.map(tokenize_func, remove_columns=chat_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3561005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_example:\n",
      "instruction: Give three tips for staying healthy.\n",
      "input: \n",
      "output: 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n",
      "2. Exercise regularly to keep your body active and strong. \n",
      "3. Get enough sleep and maintain a consistent sleep schedule.\n",
      "\n",
      "chat_example:\n",
      "prompt: <[im_start]>user\n",
      "Give three tips for staying healthy.<[im_end]>\n",
      "<[im_start]>assistant\n",
      "\n",
      "full_text: <[im_start]>user\n",
      "Give three tips for staying healthy.<[im_end]>\n",
      "<[im_start]>assistant\n",
      "1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \n",
      "2. Exercise regularly to keep your body active and strong. \n",
      "3. Get enough sleep and maintain a consistent sleep schedule.<[im_end]>\n",
      "\n",
      "tok_example:\n",
      "input_ids: [66746, 318, 4906, 25669, 872, 198, 35127, 2326, 10414, 369, 19429, 9314, 15757, 58, 318, 6213, 64077, 66746, 318, 4906, 25669, 77091, 198, 16, 5142, 266, 264, 23831, 9968, 323, 1281, 2704, 311, 2924, 11260, 315, 25322, 323, 23880, 13, 715, 17, 13, 32818, 15502, 311, 2506, 697, 2487, 4541, 323, 3746, 13, 715, 18, 13, 2126, 3322, 6084, 323, 10306, 264, 12966, 6084, 9700, 15757, 58, 318, 6213, 25669]\n",
      "prompt_len: 23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for raw_example, chat_example, tok_example in zip(raw_ds, chat_ds, tok_ds):\n",
    "    print(\"raw_example:\")\n",
    "    print(\"instruction: %s\" % raw_example[\"instruction\"])\n",
    "    print(\"input: %s\" % raw_example[\"input\"])\n",
    "    print(\"output: %s\" % raw_example[\"output\"])\n",
    "    print()\n",
    "    print(\"chat_example:\")\n",
    "    print(\"prompt: %s\" % chat_example[\"prompt\"])\n",
    "    print(\"full_text: %s\" % chat_example[\"full_text\"])\n",
    "    print()\n",
    "    print(\"tok_example:\")\n",
    "    print(\"input_ids: %s\" % tok_example[\"input_ids\"])\n",
    "    print(\"prompt_len: %s\" % tok_example[\"prompt_len\"])\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7502e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class SFTDataCollator:\n",
    "    def __call__(self, batch):\n",
    "        # convert list of tokenized samples to padded tensor batch \n",
    "        input_ids_list = [torch.tensor(b[\"input_ids\"]) for b in batch]\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(input_ids_list, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "        # Attention mask: 1 for real tokens, 0 for pad \n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "        # create labels (copy of input_ids)\n",
    "        labels = input_ids.clone()\n",
    "        # mask out prompt part (all tokens up to and including \"### Response:\\n\")\n",
    "        for i, b in enumerate(batch):\n",
    "            prompt_len = b['prompt_len'] # length of prompt in tokens \n",
    "            labels[i, :prompt_len] = -100 # ignore prompt tokens in loss \n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a88ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = SFTDataCollator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d32282",
   "metadata": {},
   "source": [
    "### Training the model with SFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8m04hzsikr6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import math\n",
    "\n",
    "class PerplexityCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            if \"loss\" in logs:\n",
    "                logs[\"train_perplexity\"] = math.exp(logs[\"loss\"])\n",
    "            if \"eval_loss\" in logs:\n",
    "                logs[\"eval_perplexity\"] = math.exp(logs[\"eval_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63amqrrgp59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and evaluation sets\n",
    "train_test_split = tok_ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = train_test_split[\"train\"]\n",
    "eval_ds = train_test_split[\"test\"]\n",
    "\n",
    "print(f\"Training samples: {len(train_ds)}\")\n",
    "print(f\"Evaluation samples: {len(eval_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"qwen_sft_demo\",\n",
    "    overwrite_output_dir=True, \n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,  # Added for evaluation\n",
    "    eval_strategy=\"steps\",  # Evaluate periodically during training\n",
    "    eval_steps=100,  # Evaluate every 100 steps\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=100,\n",
    "    logging_steps=20,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,  # Load best model based on eval loss\n",
    "    metric_for_best_model=\"eval_loss\",  # Use eval loss to determine best model\n",
    "    report_to=[],\n",
    "    bf16=True,\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,  # Use train split instead of full dataset\n",
    "    eval_dataset=eval_ds,  # Add evaluation dataset\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    callbacks=[PerplexityCallback()]  # Add perplexity tracking\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3d54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/3000 00:00 < 04:59, 10.01 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.8324340136845907, metrics={'train_runtime': 328.7333, 'train_samples_per_second': 18.252, 'train_steps_per_second': 9.126, 'total_flos': 1845623829823488.0, 'train_loss': 0.8324340136845907, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3db33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAGHCAYAAAA+xRHwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVJdJREFUeJzt3Xd4U2X7B/BvkqZJWzpoS5sWCpQhqwzZCAoKBWSLk43iZAjiAHFQEAT0RUARFEVQeRmvP0RBASkyHOylFBAQChZoqaymtLRNm+f3R0lo2oyTNG3W93NdXJqTk5PnPklz7vNMmRBCgIiIiMgCuasLQERERO6NyQIRERFZxWSBiIiIrGKyQERERFYxWSAiIiKrmCwQERGRVUwWiIiIyComC0RERGQVkwUiIiKyiskCeZ3ly5dDJpPhwIEDri6KQ0aOHInatWt7zHGlEEJg9erVuPfeexEVFQW1Wo0aNWqgR48e+Pzzz032lclkZv9FRkYaP1tb/yzFWbt2bUmvX758ebniNZTz3Llzdr/23LlzTikDkTP5uboARFQ53nrrLYwfP94l7/36669jzpw5eOaZZ/Dqq68iODgY58+fx7Zt2/D999/j6aefNtn/kUcewcsvv2yyTalUombNmti9e7fJ9g4dOpTZX6VSmS3HunXrkJ+fb3z8+eefY+nSpdi8eTNCQ0ON2+vWretwrADQu3dv7N69GzExMXa/NiYmBrt37y53GYicickCkZfLzc1FYGCgyy4+t27dwvz58zF8+HAsWbLE5LmRI0dCr9eXeU10dDTat29v9njVqlWza/+S7r77bpPHmzdvBgC0atUKkZGRFl9nOIdSVatWzWw5pVCpVJJiIapMbIYgn/Xbb7+ha9euCA4ORmBgIO655x78+OOPJvvk5ubilVdeQXx8PNRqNcLDw9G6dWusWrXKuM/Zs2fxxBNPIDY2FiqVCtHR0ejatSuOHDliswzLly9HgwYNoFKp0KhRI3z11Vdl9tmxYwdkMhl27Nhhst1cdfXIkSNRpUoVHD16FN27d0dwcDC6du1qfK509bxMJsPYsWPx9ddfo1GjRggMDETz5s3xww8/lCnH999/j2bNmkGlUqFOnTpYsGABkpKSIJPJrMaYk5OD/Px8i3fZcrl7/QxZO4fJycno378/atSoAbVajXr16uG5557DlStXTI5hrhmiS5cuSEhIwP79+3HvvfciMDAQderUwezZs00SJnOfq+E8Hzt2DIMGDUJoaCiio6Px1FNPISsry+S9b9y4gVGjRiE8PBxVqlRB7969cfbsWchkMiQlJTn9fJFvYM0C+aSdO3ciMTERzZo1w9KlS6FSqbBo0SL07dsXq1atwuOPPw4AmDhxIr7++mvMmDEDd999N3JycpCSkoKrV68aj9WrVy8UFRXhvffeQ82aNXHlyhXs2rULN27csFqG5cuX48knn0T//v0xd+5cZGVlISkpCfn5+eW6gBYUFKBfv3547rnnMHnyZBQWFlrd/8cff8T+/fsxffp0VKlSBe+99x4eeughnDx5EnXq1AFQfAc+cOBA3HfffVizZg0KCwvxn//8B5cvX7ZZnsjISNSrVw+LFi1CVFQUevXqhQYNGlhNMoQQZcqtUChsJibOYukcnjlzBh06dMDTTz+N0NBQnDt3Dh988AE6deqEo0ePQqlUWj1uRkYGhgwZgpdffhlTp07FunXr8PrrryM2NhbDhw+3Wa6HH34Yjz/+OEaNGoWjR4/i9ddfBwB88cUXAAC9Xo++ffviwIEDSEpKQsuWLbF792707NmznGeEfJ4g8jLLli0TAMT+/fst7tO+fXsRFRUlsrOzjdsKCwtFQkKCqFGjhtDr9UIIIRISEsSAAQMsHufKlSsCgJg/f75dZSwqKhKxsbGiZcuWxvcSQohz584JpVIpatWqZdy2fft2AUBs377d5BipqakCgFi2bJlx24gRIwQA8cUXX5R5zxEjRpgcVwghAIjo6Gih1WqN2zIyMoRcLhezZs0ybmvTpo2Ii4sT+fn5xm3Z2dkiIiJCSPkZ2bdvn6hZs6YAIACI4OBg0adPH/HVV1+ZxG8ok7l/n332mdljAxBjxoyxWQZzpk6dKgCIf//917jN2jksSa/XC51OJ86fPy8AiO+//974nOE7mJqaatzWuXNnAUDs3bvX5DiNGzcWPXr0MD4297kayvnee++ZvHb06NFCrVYbz+GPP/4oAIjFixeb7Ddr1iwBQEydOtVqTESWuFf9H1ElyMnJwd69e/HII4+gSpUqxu0KhQLDhg3DhQsXcPLkSQBA27ZtsWnTJkyePBk7duzArVu3TI4VHh6OunXr4v3338cHH3yAw4cPm22DL+3kyZO4dOkSBg8ebHK3XKtWLdxzzz3ljvHhhx+WvO/999+P4OBg4+Po6GhERUXh/PnzAIrP14EDBzBgwAD4+/sb96tSpQr69u0r6T3atGmDv//+G5s3b8aUKVPQoUMH/Pzzzxg+fDj69esHIYTJ/o899hj2799v8m/AgAGSY3IGc+cwMzMTzz//POLi4uDn5welUolatWoBAE6cOGHzmBqNBm3btjXZ1qxZM+O5tqVfv35lXpuXl4fMzEwAxTVmQPH5K2nQoEGSjk9kCZshyOdcv34dQgizbeixsbEAYGxm+PDDD1GjRg2sWbMGc+bMgVqtRo8ePfD++++jfv36kMlk+PnnnzF9+nS89957ePnllxEeHo4hQ4Zg5syZJhfhkgzH12g0ZZ7TaDQODbkzCAwMREhIiOT9IyIiymxTqVTGxMhwvqKjo8vsZ26bJUqlEj169ECPHj0AFJ+DRx55BD/88AM2bdqEXr16GfetVq0aWrduLfnYzmbuHOr1enTv3h2XLl3CW2+9haZNmyIoKAh6vR7t27cvk0iaY+tc2/t6w6gPw+uvXr0KPz8/hIeHm+xnz+dEZA5rFsjnVK1aFXK5HOnp6WWeu3TpEgAYe8YHBQVh2rRp+Ouvv5CRkYHFixdjz549JnfUtWrVwtKlS5GRkYGTJ0/ipZdewqJFi/Dqq69aLIPhRz8jI6PMc6W3qdVqADAZ8gegTKc6A2e361etWhUymcxs/wRz5ZcqIiICEyZMAACkpKQ4fJyKYO4cpqSk4I8//sD777+PcePGoUuXLmjTpo3ZBMBVIiIiUFhYiGvXrplsL8/nRAQwWSAfFBQUhHbt2uHbb781uaPT6/VYsWIFatSogbvuuqvM66KjozFy5EgMGjQIJ0+eRG5ubpl97rrrLrz55pto2rQpDh06ZLEMDRo0QExMDFatWmVSBX/+/Hns2rXLZF/DCIY///zTZPv69eslxVteQUFBaN26Nb777jsUFBQYt9+8edPsqInSdDqdSYfQkgxV94YaHXdmSCBKz+Hw6aefuqI4ZnXu3BkAsGbNGpPtq1evdkVxyIuwGYK81rZt28xW5/fq1QuzZs1CYmIi7r//frzyyivw9/fHokWLkJKSglWrVhkvDO3atUOfPn3QrFkzVK1aFSdOnMDXX3+NDh06IDAwEH/++SfGjh2LRx99FPXr14e/vz+2bduGP//8E5MnT7ZYNrlcjnfeeQdPP/00HnroITzzzDO4ceMGkpKSyjRNaDQadOvWDbNmzULVqlVRq1Yt/Pzzz/j222+der6smT59Onr37o0ePXpg/PjxKCoqwvvvv48qVaqUuYstLSsrC7Vr18ajjz6Kbt26IS4uDjdv3sSOHTuwYMECNGrUCAMHDqykSBzXsGFD1K1bF5MnT4YQAuHh4diwYQOSk5NdXTSjnj17omPHjnj55Zeh1WrRqlUr7N692zgk192GqZLnYLJAXmvSpElmt6empqJz587Ytm0bpk6dapwYqHnz5li/fj369Olj3PeBBx7A+vXrMW/ePOTm5qJ69eoYPnw43njjDQDFF/K6deti0aJFSEtLg0wmQ506dTB37lyMGzfOavlGjRoFAJgzZw4GDhyI2rVrY8qUKdi5c2eZORW+/vprjBs3DpMmTUJRUZFxiGdltev37NkTa9euxdtvv43HH38cGo0Go0ePxqVLl/D1119bfW1ISAimTZuGn3/+GVOmTMHly5chk8kQHx+PCRMmYNKkSXZNeOQqSqUSGzZswPjx4/Hcc8/Bz88P3bp1w9atW1GzZk1XFw9AcTKwYcMGvPzyy5g9ezYKCgrQsWNHrFixAu3bt0dYWJiri0geSiZKd0MmIpJAp9OhRYsWqF69OrZs2eLq4pAVK1euxJAhQ/D77787ZbQN+R7WLBCRJKNGjUJiYiJiYmKQkZGBTz75BCdOnMCCBQtcXTQqYdWqVbh48SKaNm0KuVyOPXv24P3338d9993HRIEcxmSBiCTJzs7GK6+8gn///RdKpRItW7bExo0b0a1bN1cXjUoIDg7G6tWrMWPGDOTk5CAmJgYjR47EjBkzXF008mBshiAiIiKr2DWWiIiIrGKyQERERFYxWSAiIiKrPLqDo16vx6VLlxAcHFxpS9cSERF5AyEEsrOzERsba3PCLo9OFi5duoS4uDhXF4OIiMhjpaWloUaNGlb38ehkwbCiX1paml2r7Fmj0+mwZcsWdO/eHUql0inHdDeM0Tt4e4zeHh/AGL2BJ8en1WoRFxdncXXckjw6WTA0PYSEhDg1WTAsT+tpH7xUjNE7eHuM3h4fwBi9gTfEJ6UZ3+UdHC9evIihQ4ciIiICgYGBaNGiBQ4ePOjqYhEREdFtLq1ZuH79Ojp27Ij7778fmzZtQlRUFM6cOcPFToiIiNyIS5OFOXPmIC4uDsuWLTNuq127tusKRERERGW4NFlYv349evTogUcffRQ7d+5E9erVMXr0aDzzzDNm98/Pz0d+fr7xsVarBVDcZqTT6ZxSJsNxnHU8d8QYvYO3x+jt8QHli1EIgaKiIhQVFcGdZ+0vLCyEn58fbt68CT8/j+4mZ5a7xieTyaBQKKBQKCz2SbDne+fStSHUajUAYOLEiXj00Uexb98+TJgwAZ9++imGDx9eZv+kpCRMmzatzPaVK1ciMDCwwstLROQO5HI5wsLCEBAQwDlmyCIhBHJzc5GVlQW9Xl/m+dzcXAwePBhZWVk2Bwm4NFnw9/dH69atsWvXLuO2F198Efv378fu3bvL7G+uZiEuLg5Xrlxx6miI5ORkJCYmemzPVlsYo3fw9hi9PT7AsRj1ej1SU1OhUChQrVo1KJVKt04YhBDIyclBUFCQW5fTUe4anxACOp0O//77L4qKihAfH19m4iWtVovIyEhJyYJL60xiYmLQuHFjk22NGjXC2rVrze6vUqmgUqnKbFcqlU75MSnSCxxKvYaDV2SIuJCNDvWioJC7z4fvbM46b+6MMXo+b48PsC/GvLw8CCFQvXp1j6hR1ev10Ol0CAgIsDlLoCdy9/j8/f1x/vx5CCHKfMfs+btyabLQsWNHnDx50mTbqVOnUKtWrUovy+aUdEzbcBzpWXkAFPjq9AHEhKoxtW9j9EyIqfTyEBFZ444XJnI/zvqeuPTb9tJLL2HPnj1499138ffff2PlypVYsmQJxowZU6nl2JySjhdWHLqdKNyRkZWHF1YcwuaU9EotDxERkTtxabLQpk0brFu3DqtWrUJCQgLeeecdzJ8/H0OGDKm0MhTpBaZtOA5zHTcM26ZtOI4ivfv2NiYiIqpILq/H6tOnD44ePYq8vDycOHHC4rDJirIv9VqZGoWSBID0rDzsS71WeYUiIqoERXqB3Weu4vsjF7H7zFWPvCnq0qULJkyYIHn/c+fOQSaT4ciRIxVWJm/kPoNCXSQz23Ki4Mh+RESewLSfVrGK7KelUCisPj9ixAgsX77c7uN+++23dnXUi4uLQ3p6OiIjI+1+L3ucO3cO8fHxOHz4MFq0aFGh71UZfD5ZiApWO3U/IiJ3Z+inVboewdBPa/HQlk5PGC5evGjsbLdmzRq8/fbbJh3cAwICTPbX6XSSkoDw8HC7yqFQKKDRaOx6DblBM4SrtY0PR0yoGpYGSMpQnG23jbfvC0lEVFmEEMgtKJT0LztPh6nrj1ntp5W0/jiy83SSjid1qh6NRmP8FxoaCplMZnycl5eHsLAw/O9//0OXLl2gVquxYsUKXL16FYMGDUKNGjUQGBiIpk2bYtWqVSbHLd0MUbt2bbz77rt46qmnEBwcjJo1a2LJkiXG50s3Q+zYsQMymQw///wzWrdujcDAQNxzzz1lRurNmDEDUVFRCA4OxtNPP43JkyeXq8YgPz8fL774IqKioqBWq9GpUyfs37/f+Pz169cxZMgQVKtWDQEBAahfv75xaYSCggKMHTsWMTExUKvVqF27NmbNmuVwWaTw+ZoFhVyGqX0b44UVhyADTP6ADAnE1L6NvXq+BSLybLd0RWj89k9OOZYAkKHNQ9OkLZL2Pz69BwL9nXMpmTRpEubOnYtly5ZBpVIhLy8PrVq1wqRJkxASEoIff/wRw4YNQ506ddCuXTuLx5k7dy7eeecdTJkyBf/3f/+HF154Affddx8aNmxo8TVvvPEG5s6di2rVquH555/HU089hd9//x0A8N///hczZ87EokWL0LFjR6xevRpz585FfHy8w7G+9tprWLt2Lb788kvUqlUL7733Hnr06IG///4b4eHheOutt3D8+HFs2rQJkZGR+Pvvv3Hr1i0AwIcffoj169fjf//7H2rWrIm0tDSkpaU5XBYpfD5ZAICeCTFYPLRlmfY7DedZICKqNBMmTMDAgQNNtr3yyivG/x83bhw2b96Mb775xmqy0KtXL4wePRpAcQIyb9487Nixw2qyMHPmTHTu3BkAMHnyZPTu3Rt5eXlQq9X46KOPMGrUKDz55JMAgLfffhtbtmzBzZs3HYozJycHixcvxvLly/Hggw8CAD777DMkJydj6dKlePXVV/HPP//g7rvvRuvWrQGYLrL4zz//oH79+ujUqRNkMlmlzE3EZOG2ngkxSGyswYsrD+LHlMvolRCNjwa3Yo0CEbm9AKUCx6f3kLTvvtRrGLlsv839lj/ZRlLza4DSesdFexgujAZFRUWYPXs21qxZg4sXLxqn/A8KCrJ6nGbNmhn/39DckZmZKfk1MTHFN4iZmZmoWbMmTp48aUw+DNq2bYtt27ZJiqu0M2fOQKfToWPHjsZtSqUSbdu2xYkTJwAAL7zwAh5++GEcOnQI3bt3x4ABA3DPPfcAAEaOHInExEQ0aNAAPXv2RJ8+fdC9e3eHyiKVz/dZKEkhl6FOteIvYVigkokCEXkEmUyGQH8/Sf/urV9NUj+te+tXk3Q8Z66HUDoJmDt3LubNm4fXXnsN27Ztw5EjR9CjRw8UFBRYPU7pjpEymczsQkqWXmOIqeRrSsdZnmWVDK81d0zDtgcffBDnz5/HhAkTcOnSJXTt2tVYy9KyZUukpqbinXfewa1bt/DYY4/hkUcecbg8UjBZKEV9O0vO01n/YhEReSJDPy0AZRIGd+un9euvv6J///4YOnQomjdvjjp16uD06dOVXo4GDRpg3759JtsOHDjg8PHq1asHf39//Pbbb8ZtOp0OBw4cQKNGjYzbqlWrhpEjR2LFihWYP3++SUfNkJAQPP744/jss8+wZs0arF27FteuVdx8QGyGKCXAmCwUubgkREQVw1P6adWrVw9r167Frl27ULVqVXzwwQfIyMgwuaBWhnHjxuGZZ55B69atcc8992DNmjX4888/UadOHZuvLT2qAgAaN26MF154Aa+++irCw8NRs2ZNvPfee8jNzcWoUaMAFPeLaNWqFZo0aYL8/Hz88MMPxrjnzZuHmJgYtGjRAnK5HN988w00Gg3CwsKcGndJTBZKUSuLK1tYs0BE3szQT2tf6jVkZuchKrh4iLg71CgYvPXWW0hNTUWPHj0QGBiIZ599FgMGDEBWVlallmPIkCE4e/YsXnnlFeTl5eGxxx7DyJEjy9Q2mPPEE0+U2ZaamorZs2dDr9dj2LBhyM7ORuvWrfHTTz+hatWqAIpXi3z99ddx7tw5BAQE4N5778Xq1asBAFWqVMGcOXNw+vRpKBQKtGnTBhs3bqzQxcVkojwNLy6m1WoRGhoqaS1uqb49+A8mfnMU99QJx8pnOzjlmO5Gp9Nh48aN6NWrl9cu/csYPZ+3xwc4FmNeXh5SU1MRHx8Ptdr9J4vT6/XQarUICQnxqpUyExMTodFo8OWXX7p1fNa+L/ZcQ1mzUIqhGeIWmyGIiAhAbm4uPvnkE/To0QMKhQKrVq3C1q1bkZyc7OqiVRomC6Wo2AxBREQlyGQybNy4ETNmzEB+fj4aNGiAtWvXolu3bjZHWXgLJgulsIMjERGVFBAQgK1bt7q6GC7lfg0sLqb2YzMEERFRSUwWSjGMhsgv9I2qJSLyTB7cN50qkbO+J0wWSgnwZ80CEbkvw6iJ3NxcF5eEPIHhe1LeEUXss1CK2u9OB8eSU28SEbkDhUKBsLAw41oHgYGBbv07pdfrUVBQgLy8PLccWlhe7hqfEAK5ubnIzMxEWFgYFIryreHBZKEUdYlFUfIL9SaPiYjcgUajAQCbiyO5AyEEbt26hYCAALdOahzl7vGFhYUZvy/lwWShlJLJwa2CIiYLROR2ZDIZYmJiEBUVBZ1O5+riWKXT6fDLL7/gvvvu88rJtdw5PqVSWe4aBQMmC6Uo5DIoZAJFQoZbuiJUdXWBiIgsUCgUTrsYVBSFQoHCwkKo1Wq3u5g6g7fHZ+A+DSxuxP/2WeFcC0REREwWzDIkCxwRQURExGTBLCVrFoiIiIyYLJhh6NPI9SGIiIiYLJhlbIYoYM0CERERkwUzlPLi6THzCpksEBERMVkwgzULREREdzBZMIMdHImIiO5gsmDGnXkW2MGRiIiIyYIZhtEQnGeBiIiIyYJZSk7KREREZMRkwQxO90xERHQHkwUz/A1DJ5ksEBERMVkwR8mhk0REREZMFsxQcjQEERGREZMFM7jqJBER0R1MFszg0EkiIqI7mCyYYahZyGeyQERExGTBHM6zQEREdAeTBTMMQyeZLBAREbk4WUhKSoJMJjP5p9FoXFkkABwNQUREVJKfqwvQpEkTbN261fhYoVC4sDTFjMkC51kgIiJyfbLg5+fnFrUJJRmney5kskBEROTyZOH06dOIjY2FSqVCu3bt8O6776JOnTpm983Pz0d+fr7xsVarBQDodDrodDqnlEen08H/duWGrkggNy8fSoV3de0wnCtnnTN3xBg9n7fHBzBGb+DJ8dlTZpkQQlRgWazatGkTcnNzcdddd+Hy5cuYMWMG/vrrLxw7dgwRERFl9k9KSsK0adPKbF+5ciUCAwOdVi6dHnhlb3EeNadNIdQuT6mIiIicKzc3F4MHD0ZWVhZCQkKs7uvSZKG0nJwc1K1bF6+99homTpxY5nlzNQtxcXG4cuWKzUCl0ul02LIlGS/t8YMAsHtSZ0RWUTnl2O5Cp9MhOTkZiYmJUCqVri5OhWCMns/b4wMYozfw5Pi0Wi0iIyMlJQtudc8cFBSEpk2b4vTp02afV6lUUKnKXriVSqVTPySZDFAr5bil06NQyD3uCyCVs8+bO2KMns/b4wMYozfwxPjsKa9bNcbn5+fjxIkTiImJcXVRoL495zPnWiAiIl/n0mThlVdewc6dO5Gamoq9e/fikUcegVarxYgRI1xZLABAwO1kIY/JAhER+TiXNkNcuHABgwYNwpUrV1CtWjW0b98ee/bsQa1atVxZLADFzRAAcItzLRARkY9zabKwevVqV769VWyGICIiKuZWfRbcyZ1mCE75TEREvo3JggWq280Q7LNARES+jsmCBQFshiAiIgLAZMEiNUdDEBERAWCyYJFxNASTBSIi8nFMFiwwdnDk0EkiIvJxTBYsUPnd7uBYyNEQRETk25gsWGDs4MiaBSIi8nFMFizgpExERETFmCxYoOY8C0RERACYLFjEhaSIiIiKMVmwQM3pnomIiAAwWbCI8ywQEREVY7JgAUdDEBERFWOyYIGxGaKQyQIREfk2JgsWGEdDsGaBiIh8HJMFCzjPAhERUTEmCxbcmWeBoyGIiMi3MVmwwF9xZzTE7jNXUKQXLi4RERGRazBZMOOPqzI8/Mle4+NBn+1FpznbsDkl3YWlIiIicg0mC6X8dOwyvjglx+XsfJPtGVl5eGHFISYMRETkc5gslFCkF5ix8S+zzxkaIaZtOM4mCSIi8ilMFkrYl3oNGdp8ADKzzwsA6Vl52Jd6rVLLRURE5EpMFkrIzM5z6n5ERETegMlCCVHBaqfuR0RE5A2YLJTQNj4cmhAV7vRQMCUDEBOqRtv48EotFxERkSsxWShBIZfhzV4NAZTttWB4PLVvYyjk5vs0EBEReSMmC6X0aBKNp+7SIzpEZbJdE6rG4qEt0TMhxkUlIyIicg0mC2Y0jxDY8fJ9qBUeCACY/GBD/DbpASYKRETkk5gsWKCQyxAWqAQA1I+qwqYHIiLyWUwWrPC7vT6EroiLSRERke9ismCFUlFcm6Ar4oyNRETku5gsWKG8XbNQqGfNAhER+S4mC1b4yVmzQERExGTBCkOfhUImC0RE5MOYLFhh6LPAZggiIvJlTBas8JMbRkOwZoGIiHwXkwUr/IyjIVizQEREvovJghX+xj4LTBaIiMh3MVmwwo/zLBAREblPsjBr1izIZDJMmDDB1UUxMvRZYAdHIiLyZW6RLOzfvx9LlixBs2bNXF0UE8bREKxZICIiH+byZOHmzZsYMmQIPvvsM1StWtXVxTFxZ20IJgtEROS7/FxdgDFjxqB3797o1q0bZsyYYXXf/Px85OfnGx9rtVoAgE6ng06nc0p5DMfR6XSQozhJyNcVOu347qBkjN6KMXo+b48PYIzewJPjs6fMMiGEy26bV69ejZkzZ2L//v1Qq9Xo0qULWrRogfnz55vdPykpCdOmTSuzfeXKlQgMDHR6+X66IMPGNAU6ROnxRF32WyAiIu+Rm5uLwYMHIysrCyEhIVb3dVnNQlpaGsaPH48tW7ZArVZLes3rr7+OiRMnGh9rtVrExcWhe/fuNgOVSqfTITk5GYmJiUjbfQEb004jpnoN9OqV4JTju4OSMSqVSlcXp0IwRs/n7fEBjNEbeHJ8htp5KVyWLBw8eBCZmZlo1aqVcVtRURF++eUXLFy4EPn5+VAoFCavUalUUKlUZY6lVCqd/iEplUqo/YtPj17A474EUlTEeXM3jNHzeXt8AGP0Bp4Ynz3ldVmy0LVrVxw9etRk25NPPomGDRti0qRJZRIFVzCuOqlnB0ciIvJdLksWgoODkZBgWrUfFBSEiIiIMttdxY8zOBIREbl+6KQ7U3IGRyIiItcPnSxpx44dri6CCaVxngXWLBARke9izYIVd5ohWLNARES+i8mCFcrbHRy5NgQREfkyJgtWcLpnIiIiJgtWGZaoZs0CERH5MiYLVihvL1GtK2TNAhER+S4mC1YYh06yZoGIiHwYkwUrOBqCiIiIyYJVhpoFzuBIRES+jMmCFX6GPgtcG4KIiHwYkwUrWLNARETEZMEqzrNARETEZMGqOwtJsWaBiIh8F5MFKwwLSRWyzwIREfkwJgtW+N1eG6JILyAEEwYiIvJNTBasMPRZANhvgYiIfBeTBSsMfRYArg9BRES+i8mCFYZ5FgCuD0FERL6LyYIVJWsWuD4EERH5KiYLVshkMmMnR64PQUREvorJgg1+nGuBiIh8HJMFG5RyzrVARES+jcmCDX5cH4KIiHwckwUbDHMtFDBZICIiH8VkwQZ/w5TP7OBIREQ+ismCDcZmCA6dJCIiH+VQspCWloYLFy4YH+/btw8TJkzAkiVLnFYwd2EYOsnpnomIyFc5lCwMHjwY27dvBwBkZGQgMTER+/btw5QpUzB9+nSnFtDVlGyGICIiH+dQspCSkoK2bdsCAP73v/8hISEBu3btwsqVK7F8+XJnls/ljPMssBmCiIh8lEPJgk6ng0qlAgBs3boV/fr1AwA0bNgQ6enpziudGzCsD6ErZLJARES+yaFkoUmTJvjkk0/w66+/Ijk5GT179gQAXLp0CREREU4toKspjR0c2QxBRES+yaFkYc6cOfj000/RpUsXDBo0CM2bNwcArF+/3tg84S0MfRY43TMREfkqP0de1KVLF1y5cgVarRZVq1Y1bn/22WcRGBjotMK5Az92cCQiIh/nUM3CrVu3kJ+fb0wUzp8/j/nz5+PkyZOIiopyagFdTSnnPAtEROTbHEoW+vfvj6+++goAcOPGDbRr1w5z587FgAEDsHjxYqcW0NXurDrJmgUiIvJNDiULhw4dwr333gsA+L//+z9ER0fj/Pnz+Oqrr/Dhhx86tYCudqcZgjULRETkmxxKFnJzcxEcHAwA2LJlCwYOHAi5XI727dvj/PnzTi2gqyk5gyMREfk4h5KFevXq4bvvvkNaWhp++ukndO/eHQCQmZmJkJAQpxbQ1YyjIdhngYiIfJRDycLbb7+NV155BbVr10bbtm3RoUMHAMW1DHfffbdTC+hqHA1BRES+zqGhk4888gg6deqE9PR04xwLANC1a1c89NBDTiucOzBOysQ+C0RE5KMcShYAQKPRQKPR4MKFC5DJZKhevbrXTcgElJjumTM4EhGRj3KoGUKv12P69OkIDQ1FrVq1ULNmTYSFheGdd96B3o62/cWLF6NZs2YICQlBSEgIOnTogE2bNjlSpArDmgUiIvJ1DtUsvPHGG1i6dClmz56Njh07QgiB33//HUlJScjLy8PMmTMlHadGjRqYPXs26tWrBwD48ssv0b9/fxw+fBhNmjRxpGhOx3kWiIjI1zmULHz55Zf4/PPPjatNAkDz5s1RvXp1jB49WnKy0LdvX5PHM2fOxOLFi7Fnzx63SRa4NgQREfk6h5KFa9euoWHDhmW2N2zYENeuXXOoIEVFRfjmm2+Qk5NjHF1RWn5+PvLz842PtVotgOIls3U6nUPvW5rhOIb/ylFco1BQWOS093C10jF6I8bo+bw9PoAxegNPjs+eMsuEEHbXr7dr1w7t2rUrM1vjuHHjsG/fPuzdu1fysY4ePYoOHTogLy8PVapUwcqVK9GrVy+z+yYlJWHatGlltq9cubLCFrD6+aIM6/9RoE01PYbWY+0CERF5h9zcXAwePBhZWVk250hyKFnYuXMnevfujZo1a6JDhw6QyWTYtWsX0tLSsHHjRuNU0FIUFBTgn3/+wY0bN7B27Vp8/vnn2LlzJxo3blxmX3M1C3Fxcbhy5YrTJoPS6XRITk5GYmIilEollu06j3c3nUSfphrMe6yZU97D1UrH6I0Yo+fz9vgAxugNPDk+rVaLyMhIScmCQ80QnTt3xqlTp/Dxxx/jr7/+ghACAwcOxLPPPoukpCS7kgV/f39jB8fWrVtj//79WLBgAT799NMy+6pUKqhUqjLblUql0z8kwzHV/sWnSH97mzepiPPmbhij5/P2+ADG6A08MT57yuvwPAuxsbFlOjL+8ccf+PLLL/HFF184elgIIUxqD1zNMM9CQSFHQxARkW9yOFlwhilTpuDBBx9EXFwcsrOzsXr1auzYsQObN292ZbFMGOdZ4NoQRETko1yaLFy+fBnDhg1Deno6QkND0axZM2zevBmJiYmuLJYJJdeGICIiH+fSZGHp0qWufHtJ7kzKxJoFIiLyTXYlCwMHDrT6/I0bN8pTFrdk6LNQyLUhiIjIR9mVLISGhtp8fvjw4eUqkLvh2hBEROTr7EoWli1bVlHlcFt+t/ssFLDPAhER+SiHVp30JaxZICIiX8dkwQbjaAj2WSAiIh/FZMEGPzlHQxARkW9jsmAD51kgIiJfx2TBBj/O4EhERD6OyYINd9aGYLJARES+icmCDf7s4EhERD6OyYINxmYI9lkgIiIfxWTBBuPaEOyzQEREPorJgg3K230WhACK2BRBREQ+iMmCDYaaBYBzLRARkW9ismCDYZ4FgMkCERH5JiYLNhhmcATYyZGIiHwTkwUbFHIZZLfzBXZyJCIiX8RkwQaZTGbs5MiaBSIi8kVMFiTgXAtEROTLmCxIYFx5ks0QRETkg5gsSGAYEcHREERE5IuYLEjAZggiIvJlTBYkYM0CERH5MiYLEii58iQREfkwJgsSGDs4smaBiIh8EJMFCfwUnGeBiIh8F5MFCZQK1iwQEZHvYrIgwZ1mCNYsEBGR72GyIMGdDo6sWSAiIt/DZEECJfssEBGRD2OyIIEf+ywQEZEPY7IggZ+c8ywQEZHvYrIgAUdDEBGRL2OyIIGfcbpn1iwQEZHvYbIggdK4kBRrFoiIyPcwWZBAyT4LRETkw5gsSMDREERE5MuYLEjAeRaIiMiXMVmQwDjdM2dwJCIiH8RkQQLjaIhC1iwQEZHvcWmyMGvWLLRp0wbBwcGIiorCgAEDcPLkSVcWySx/w2gI1iwQEZEPcmmysHPnTowZMwZ79uxBcnIyCgsL0b17d+Tk5LiyWGVwngUiIvJlfq58882bN5s8XrZsGaKionDw4EHcd999LipVWX6cZ4GIiHyYS5OF0rKysgAA4eHhZp/Pz89Hfn6+8bFWqwUA6HQ66HQ6p5TBcJySx5OjuEahoLDIae/jSuZi9DaM0fN5e3wAY/QGnhyfPWWWCSHcom5dCIH+/fvj+vXr+PXXX83uk5SUhGnTppXZvnLlSgQGBlZY2Xamy/DtOQXujtBj5F2sXSAiIs+Xm5uLwYMHIysrCyEhIVb3dZtkYcyYMfjxxx/x22+/oUaNGmb3MVezEBcXhytXrtgMVCqdTofk5GQkJiZCqVQCAP67Lw1JG04gsVEUFg1u4ZT3cSVzMXobxuj5vD0+gDF6A0+OT6vVIjIyUlKy4BbNEOPGjcP69evxyy+/WEwUAEClUkGlUpXZrlQqnf4hlTxmgH/xadILeNyXwZqKOG/uhjF6Pm+PD2CM3sAT47OnvC5NFoQQGDduHNatW4cdO3YgPj7elcWxyO/22hA6rg1BREQ+yKXJwpgxY7By5Up8//33CA4ORkZGBgAgNDQUAQEBriyaCY6GICIiX+bSeRYWL16MrKwsdOnSBTExMcZ/a9ascWWxyuDaEERE5Mtc3gzhCbg2BBER+TKuDSGB0jiDI5MFIiLyPUwWJLjTZ8EzakKIiIicicmCBKxZICIiX8ZkQQKlcdVJ1iwQEZHvYbIggWGeBTZDEBGRL2KyIIGhzwKbIYiIyBcxWZBALitOFnLyC7H7zFUUsTmCiIh8CJMFGzanpGP40r0AgJyCIgz6bA86zdmGzSnpLi4ZERFR5WCyYMXmlHS8sOIQ/r1ZYLI9IysPL6w4xISBiIh8ApMFC4r0AtM2HIe5BgfDtmkbjrNJgoiIvB6TBQsOnL+O9Kw8i88LAOlZediXeq3yCkVEROQCTBYsyMzOl7if5YSCiIjIGzBZsCAqWCVxP3UFl4SIiMi1mCxY0LpWVcSEqiGz8LwMQEyoGm3jwyuzWERERJWOyYIFCrkMU/s2BoAyCYPh8dS+jaGQW0oniIiIvAOTBSt6JsRg8dCW0ISaNjVoQtVYPLQleibEuKhkRERElcfP1QVwdz0TYpDYWIMZPx7Hst/PoU3tqlj9bAfWKBARkc9gzYIECrkM99SNBADkF+qZKBARkU9hsiBRbFhxU8SlG7dcXBIiIqLKxWRBotjQAADAlZsFyNMVubg0RERElYfJgkRhgUoEKBUAiteGICIi8hVMFiSSyWSIMTRFZLEpgoiIfAeTBTtUDytuirh0gzULRETkO5gs2CHm9nwL6ezkSEREPoTJgh1iDTULbIYgIiIfwmTBDoYREWyGICIiX8JkwQ7GmgU2QxARkQ9hsmCHmBITMwkhXFwaIiKiysFkwQ6GZoicgiJo8wpdXBoiIqLKwWTBDgH+ClQNVAIA0tnJkYiIfASTBTsZhk9+e+gCdp+5iiI9myOIiMi7MVmww+aUdJz5NwcAsOSXVAz6bA86zdmGzSnpLi4ZERFRxWGyINHmlHS8sOIQ8gv1JtszsvLwwopDlZIwFOkFdp+5iu+PXGStBhERVRo/VxfAExTpBaZtOA5zl2YBQAZg2objSGysgUIuq5AybE5Jx7QNx5FeYhGrmFA1pvZtjJ4JMWbLvC/1GjKz8xAVrEbb+PAKK1t5eUpZPaWcRETOxmRBgn2p10wu0qUJAOlZedhz5io61o90+vsbajVKJyvpWXl4fsUhvNStPsY+UN944TKXWIQHKfFQi+ro1liDu2sEO72MjrI3CaospROD6zkFeOdH9ysnEVFlYLIgQWa2tBkbx6w8hNkPN3XqxcNarYbBvK2nsWpfGpL6NQYAs4nFtRwdlv5+Dkt/PwdNiAq9NDL0KvU+lX3XbCkJMjTtLB7a0iUXYnMJjDmuLicRUWVhsiBBVLBa0n43bumcfvGwVathkKEtrmUIC1RaTSwA4LI2H19o5Wh57DL6tKhRaXf3JROSyCAVktY7r2mndLLjaO2JpQTGnMpqgiIicjUmCxK0jQ9HTKgaGVl5ki4izrx4SK3VMLiRq7O5jyGGmZv+glyuwJiVFX93L/VuvWQZ07PysC/1GjrUjbD72OZqT2yRUotTnnISEXkqjoaQQCGXYWrfxpL2LXnxkMLWCAeptRr2kyE9Kx9vfp9i8e4eKE58rI26kDJCw3C3LjVRKMlWsmTp2Je1+fjilBw/Hbss+b2k1uI4Uk4iIk/GmgWJeibEYPHQlpi89ihu3LJ99y7l4iGl+t/eWg17XcspsPicIfGZl3wKHetFGvsxGKr8k49n4Lsjl0yOUbr8jtytl2QtWbI1SgUorj15sFl1SbU85bngV1xSR0TkekwW7NAzIQbBaiWGfL7X5r5RwWqrnQaldu4z1Gq8sOJQBUQkzcLtf2Ph9r8RE6pGv+YxWP9HusU78NLld/RuXQYgOkQFvRD4/shFs50ubR+7uPZEahOBIxd8GQBNaHHZiIi8lUuThV9++QXvv/8+Dh48iPT0dKxbtw4DBgxwZZFsal8nwuadvlwGbPvrMib+74jZWoPExhq75m3omRCDMffXxcLtZ5wYiUB4kD+u5diuJTFIz8rDp7+k2jhqcfmT1h9DsFqJn45l2F0y2e3j5BXqTRKz0rUWUmsCpO7naC3O1L6N2bmRiLyaS/ss5OTkoHnz5li4cKEri2EXKf0X9AL47NfUMne9hrvuhdtOS5q3YV7yKWM/gKLbV6/GMc6bI2FwmzhoQtRw9mVOAMjQ5mPI53vx1e7zdr/e36/4a1m6s2bp2TKl1gRI3c+evikAEKBUcNgkEfkEl9YsPPjgg3jwwQddWQSH9EyIwceD78bYVYdhz4zLhrvuZb+fk7S/ofo/PEgJP3nxBXTEPbURGqCU3HeiU70IHE/PNtM3QYaFO85KGmpZGdrUroqCQj3+uJBVZkptA0M5p6w7ils6PaKqqKAJUeOy1lJNQHHtSataVSWXo2dCDF7ufhf+s+WUyfaYUDWig1U4ciEL9aKC8HdmDiKr+DNRcCHOqElUeTyqz0J+fj7y8/ONj7VaLQBAp9NBp5NenW6N4Ti2jheiVtiVKBgIQNJFvqSSTQX/+ekkpvZphAWPN8OI5QdtvvbZTrXRNj4ci3eexYJtZZsxsiQMtawMtcMD8M2hS5L2vZajw0trjgAAwgL8rCQ7MlzL0aHdu1vRv3kMujWKQutaVW1eUGS3j1izagD+uX4LCjmwedw96LVwFwDglW71MXrVEaRdv4Wlv/yNBppgScd1NqnfVU9lLb6fjl3GjI1/IUN75/dAE6LCm70aokeT6EorY3l5+2cIeH+MnhyfPWWWCSHc4cYSMpnMZp+FpKQkTJs2rcz2lStXIjAwsAJLV9bBKzJ8dVrh8OsD/QRyCwHY3QhQ/HGNrK/Hd+fluFFg/Rih/gIP1bK1b3Gdx32aIuy+LIdOVP7dmQzidmSOnQ+prwvzFxhYW4/mEZa/9p/9JUfKdTn61yrCtktyZOtkGNWgCEtPFn/ew+oWYeVZOYpKnCcpx3VXegGc0cqg1QEhSqBuiIA736D/cVWGL04ZWlBLFrT43D91l2d+DkSVLTc3F4MHD0ZWVhZCQkKs7utRyYK5moW4uDhcuXLFZqBS6XQ6JCcnIzExEUql0uJ+e1OvYegXBxx+n3H318FH28869NriHvgqvN6zAcav+RMALN5dy6w8V9rcRxKwcl8aDv6T5VC5XE1KrIZLy0dPNDd7ByqEQLvZO3A9V4f/PdsWn/16DsknMtGhTjh2n72G6GB/ZGYXlHkfW8etCFK/q9a46x16kV5gz5l/sW33QTzQoRXa161mHLbbZe4vJuUtyfC3sX3ifR7RJOGMz9DdeXuMnhyfVqtFZGSkpGTBo5ohVCoVVCpVme1KpdLpH5KtY3aoF1Wu+Q9W7E2DUi6DzoG2jOIOkPmoFhKIxUNbImn9MYs/nvYc/a31J5BbUGR3edyFPVM0z9x0ssz8C0V6ge+OXMT1XB2Uchma1ghHq9paJJ/IxO6zxZNsXc8ttDqKxdxxK5qj3//NKekYt/qPMvFc1uZj3Oo/3GRtDgW+On3EOBImNMDf4ncduPO3cfhCtkfNqFkRv2Huxttj9MT47CkvZ3B0UMme845cFq7n6hxKFErKzM5Dz4QYzH2sRbmOY+BooqDy86yvkbnRJptT0tFpzja8/L8/AAA6vcADc3fg+EXTWpaCIvOdL0seV+rsna4kZUIrW7N3VgRLM3IaRsJsPS5tKC5n1CRyLpfWLNy8eRN///238XFqaiqOHDmC8PBw1KxZ04Ulk8Ywq6M9ax44k2FI4JWblu+0KkOQyg/5hZZngnRXhtEmVVQK3MwvmyilZ+Vh/Z/pdh/XcKFy5976Upddr8w1L2wlMDIA645clHQszqhJ5FwuTRYOHDiA+++/3/h44sSJAIARI0Zg+fLlLiqVfXomxOCBhtFoP+tnq1MnO1PpWQNd9cMoA1A1SFlpcVcUc4lCeUQFqyttJU97GRKYTSnSkqDKvEOXksBcy9EhPMgf13PK9hsBOKMmUUVxabLQpUsXuEn/ynI5eP56pSYKgOmsgbZmHjT8gL7VuzGmrJM2P4PUcjzUojqWSpw3Aiie3dJazbat592Z4TxfzymQtJKnpZoHe2ok9KK4s+3V3EKbx0g+nmF3LVh5E1F7YsnQSivXgBaxZucqMfe34Uyll1iHrLhWr+T/24rRWUupE1U2j+rg6K6cefc1vEMt9GisAWTAzycul1moSWPm7rTk+hGlRwSU/AHtmRCD0EBpa1vYoinR4UxKsjD2/nroWC/SeCGFhXIuHHQ3qgapkJF1C+/8eMLiHaQ1rkw43urdCO/8aHsqb70eeOfHsjUP5tbesFQj8dOxy5h2SIEbew7YPEZYoFLS8uUGzrhDt6d2ZXNKOt754Zik4yY21qBtfDhG//eQyedcReWHx1rXQGiAP4r0wqkJgz1LrFuL0VlLqVdU85Y7N52RazFZcAJnNgM8mBBjbCPuWC8Sb/RuLOmP11L/idLJRfs6EdCEqG7fxUn7ETAkIC91q4/akUFl7mCl1Gq8lHiXsdyL5bbLCQAB/gqzCZC1cgLFCUeIWoHPNu3F0Sw1rlXCxFNqpRzzH2+B0AB/SX0BRq8suzCYpbU3DDUSHw8uTqQys/Nw7kou5m89Vea8WDqGPYmCgaU7dCkXFKkLpVnbt7SSCUxuQaExUahbLQhn/s1Bdn4hlv5+Dkt/P+e0Jp8ivcDCbX9j3tZTtne+LT0rD8+vOISXutXH2AfqQyGXWYzxsjYfX2jlaHnsMvq0qGHz2BXZvOWuTWfOwCSo/JgsOIEzlpG2dCenkMskdzDrmRCDxMYaq38UCrkMb/ZqiLGrj5ithRAoexdq7kJe8nhSajVKlkFKOQ37mUuALN09lyynTqfD1doCD9dshBdvz0XhbOFBSgxrXxsLfj4NCCAnvxApF7VOfx/DOTU/vbjzf/DkMuDJe2qbvUOXckGR0lHRsFAabv+/1L8bw3fp3JVcAECw2g9n/s0ps19GiQt26QTXktIXlOs5BZj+g+VhybbM23oaq/al4e0+jfDOjyccWkq9ZJksJYjmEjB72ZPceRpnJUG+nnAwWXACWxdMcxdglNoHcE5bq5TkokeTaDx1lx4bMwJNJ+MpsSqmPX8UUms17C2n4diWyvNaz0ZWy6kXwJxNJ22+h70M7/DuQ02h1xdfXPMK9Xj5m4pJSgwqummlXXw49qZeg16gzB16YmONxTvs0hfmK9n5kmpX9py5CrlcJqlqv4pKgf882tz4XUq9Wpwg5OnMd041nKp5W08bt1m7QNjTzGCPDG0eRq88bGMv80upSy2TuZVqSzJ3kQNg0v8iab315M6wiqyUfhnuxFISZK72xxzDuUs+nlGmSdjwferaINLi60r3b/Gkc1cakwUnsXXBNFzwzH3prF1UK0rzCIHXhtyHwxeyzV5s7R0uJ7W2wBGWEgtbCccZrczhu0LAdg0GALMdGT3VXjPzQxgSgdAAP2TdKjT7OnMXZinGrDyEh1tWl7RvI02Iyd/HuSvFyYKuSPrZt3SXLLUZpKKV7Ptkb5ksDXU1l3CEBRZPxCO1aarkKrLGYwQo8WTH2mYvtO7SidNaDZeBofYnqZ+0PiYlGb5PHz3R3K7XeWrTDpMFJ7J1wexQNwId6kZI7odQ0exp4nDF8cpLW46uCiXvOMzVYABApznbXH6BqWiG+CwlCuVx45ZO8kiavy5r8f3hi4gKKT7/hmTBHiVXLX2gYTT8/eSSLiiVxdD3qTxlkpJwONJ/pbQbt3SYt/U0lu06h9kDm5r0P7HVibOy7rptDcU1yNA61o/mzqytf+G1RpD8Omu1Gu5cI8FkwcmkXDDd7aLqrUIcmHnVXNZv7vPafeaqSybi8j3FP8nZeUUYf3ul0ZhQdblmDb2Wo0P7WT/j3YcSbHZIrRzFnYRLNg84WiZnJBz2uJGrM3a+PZ2ZY7aZqmQnTj8/RaXddUsdimtgaMYp0gtMWZciefr49Kx8bEqTI+LMVYvNOeaUrtVw9xoJJgvkteqGCGhCVLiszbc4UiM6RIW5j7WwO3vndMKuU7IjcWQVf1y5af8cJ9dyCvDCikMYeU8t5xbOQW882ND4vXPku1W6g3R5Eg57CQBjVh62eJE0bJ+8LgU5+UVWL6bmmopsdSw0dzf+84nL+ObgBbtiSM/Kw8Jtf+PL3am4lmNf7cuWi3JsWX7QrtcAd2o1nr0vHkt+SbX73FQmJgvkteQy4M1eDTFu9R8WR2ok9WuCjvXKdlCyhdMJu07Jz/GNXo3w0u31PBw5zvJd551SJkf5yYGOUQJhgUrjyBNHvlsCwBNt4oyPKzuZtX03LZM0U2rpzprmJhIreYft7I6p9gyRdRYB4LNfrScKhv0A02a0yuRZKwAR2alHk2gsHtoSmlDTH2BNqLpcGbphuKytOojIKv4OHZ8MrJ9hTWgAXupW3+GjO1pNP75rPfz36XZY8EQL/HdUO0zo6lgZCvXAzgw5hn5xAJ3mbMPmlHTjd8te87aeNh4jskrZ1Xk9Rcm7fEuLij2/4hDGrjyE580874nsGelkaEbbLHHKdmdhzQJ5vYoYqWFtuGxJhZ46d7WHyMzOw9gH6mPVvjS726gdERHkj5kPJZRJMjvWj0R2nvQOm+aUnHzriTY1HbrLNXSeC/JXOFyOksID/XEt1zVrvyz73fzdtmHbDw4s8uYtDM1oldkkwZoF8gmGTor9W1RHh7oRTulVbBguW7rWoqSsSpg90pdFBqmgkMuQ1K8xZKiIKaruCA9SYvfrXS3+OHe7PcmUo8Ttf2NXHS53dXiOg8vNlzbmgXpOOY4jnLGGjberzGXkmSwQlUPPhBjsfPV+hAeZb24w/Bnbyk1KPx8TqsZz98U7VB3tKHsutFVUfna/xt4LefE5sf5D+PI3f2BzSrrFxE3mhOzBkIS8+1BTq+3EUpumbHF1ZVTJ8kcE+aMjR24Zhaj9EOjvHpfNknNrVAb3iJrIg0lZddRwASh9ITFciBYOuhurnmmPBU+0wKpn2uO3SQ/g9V6N8dukB4zb/zuqHTQh0i9GlhIOS9s1oWosGny3zQteeJASh95KxCc2alVKxzi+q/S7VBmAp26PVLBWlsu3e5MbEoaS52vVM+3x8aCW5b54S+3fYmiaslVmd6cJVaPLXdUAAEcvZuHS7T4B/VvEICzAdDyyJ8dpr/AgJQ68mYi+zWPtel3VQD+8WIE1NJXVmZV9FojKSeof61Mda2NTSobkKbGBsnM8JPWzPq24ubUQLE2LbWm7XC6zutaH4Q7bXF+Q6zkFZVbTLDmL6ZoDF2yuoVJyGl39v2fxY3oALmebT8bMTXVcek6MxfKWmLzWvqXZw4OUeKtPE2hC7OvfYmkmV3c39v66qB8dbPwerDt8ETtO/Yvtf2Ui9UoOZDJgev+mqKLyw77Ua/h69zlsTMlA61phOHD+hltMamVLyan3s3J1kstc+nsf6G/fZfN6biE61I1E49gQTFl31O5hmbZU1sgsJgtE5ST1jzWxsabcs3c6cx0OS9vteQ9zx+iRYLkzqa1OoSVntdPpdGgeIdD5nqYYYWUMu6WpjkvGE6yWvjS7ocnB0Y5jpZOokjPxRQap8PI3f+Cy1vFF5ypCx3rVTM5d0+qhAICzt2fKrBUeiCoqP+PnnVdYhI0pGbiWq8P0/k3w1vemy4vbuyR6ZSg5TfsLK8qu+mpJeIlOrZtT0rHMgU6smdl56N+iOm7p9Hjp9uRi5eWMZeTtwWSBqJxsrTpa8o/aGbN3Gi5Gu//OxJZf96L7ve3QoV6UU6eCLc8IEmsxWltJ1FKyc9VGE4+BtRqe9nUiJK0M66xZ8qydA0PtUHk462Js6YLzd2a2yeNzV3PRac4247kpmUwYOtjdFV0FY+6vZ/yuJB/PQNJ6x1ftdIbwICUealEd3RprTL6/i4dKr216s3cj9EyIMc6K6QjDDYUmRHotgAxA6O1aEEDair4VickCUTk5sky3M96zXXw4rp4QaFdBc8ZX1LTk9iYiUcHS5gywVsMjZairrRUIncWQMNlbJV26aaS8F2NL383NKekYa2alzNIzCMaEqpGelYevdhdPbPVAw2j0b3FnYTDD5/zh1pNYsO1vlO7hYG3IsaPGd62HtvERNmdktae2SRMaAMCxWTFLJ2O2bixKvg4AZg9sCgB21SRWFCYLRE7gSPOAL7MnEWldq6rkmhtrHKnVqCg9E2LsqpI21zRiuBhbWjq8JHMrTZr7blpbU6J0/5CE2BCkZ+UZmypa1Qwr8xqFXIax99dF9oVT2JgRaJLYaELVeKt3I7zz4wmbF09b5DJg4aCW6NVM+mdoq7ap9PfK3o6E5pIxqfOzlP5sKmpFX3swWSBykopcptuXObPmxp0+I6lV0pYmggKKz834bvXRQFOlTBJUugoegM24bd09l5xdcfdZ0yF7b36fgiIhzJazeYTAa0Puw+EL2RY71JaHXgBVLQxftsTe75W9HQkt3ShYSlotNZkYyurqxQeZLBA5kTv8UXsjZ9bcuMtn1DY+HJoQ1e2ZJ80nK4aJoGytAyA1CbIVt9S7Z3M1GZnafKuzCtrqUFve/g2ODCG053slpQlB6igad0papWKyQEQewRN/YK1RyGV4s1dDjF19xOYwVanHK28SVJ5heOaGsUplT5OKJY6WXer3ynoTgoAMMrtG0bhL0ioVJ2UiIo9REdN2u1KPJtF46i49okNMO3GWd6EzR5V3FsryzCpoaFL5ZGjLMhOGWfuYZSjud1KeIYRSv1eWZgoN8wc+eqK5V/dNYs0CEZELWWvPr2y22vGldkIsz6yClib7GrOyuF+Dq4cQli5fRKAf/j2+Bz2aRFfK+7sKkwUiIhdzpyppa+34T7SJw7ytp20eo7yzClqaidNdRhuVLJ9Op8PGE5X69i7BZIGIiExYascHgNX708o9jNWZZfL0pihPwWSBiIjKsFTbUdkTkEkpE1U8dnAkIiLJLHXyc1WnTKocrFkgIiK7sEnA9zBZICIiu7FJwLewGYKIiIisYrJAREREVjFZICIiIquYLBAREZFVTBaIiIjIKiYLREREZJVHD50Uonj+MK1W67Rj6nQ65ObmQqvVQqlUOu247oQxegdvj9Hb4wMYozfw5PgM107DtdQaj04WsrOzAQBxcXEuLgkREZFnys7ORmhoqNV9ZEJKSuGm9Ho9Ll26hODgYMhkzpk5TKvVIi4uDmlpaQgJCXHKMd0NY/QO3h6jt8cHMEZv4MnxCSGQnZ2N2NhYyOXWeyV4dM2CXC5HjRo1KuTYISEhHvfB24sxegdvj9Hb4wMYozfw1Phs1SgYsIMjERERWcVkgYiIiKxislCKSqXC1KlToVKpXF2UCsMYvYO3x+jt8QGM0Rt4e3wGHt3BkYiIiCoeaxaIiIjIKiYLREREZBWTBSIiIrKKyQIRERFZxWShlEWLFiE+Ph5qtRqtWrXCr7/+6uoiOWTWrFlo06YNgoODERUVhQEDBuDkyZMm+wghkJSUhNjYWAQEBKBLly44duyYi0pcfrNmzYJMJsOECROM27whxosXL2Lo0KGIiIhAYGAgWrRogYMHDxqf9+QYCwsL8eabbyI+Ph4BAQGoU6cOpk+fDr1eb9zH0+L75Zdf0LdvX8TGxkImk+G7774zeV5KPPn5+Rg3bhwiIyMRFBSEfv364cKFC5UYhXXWYtTpdJg0aRKaNm2KoKAgxMbGYvjw4bh06ZLJMTw5xtKee+45yGQyzJ8/32S7u8doDyYLJaxZswYTJkzAG2+8gcOHD+Pee+/Fgw8+iH/++cfVRbPbzp07MWbMGOzZswfJyckoLCxE9+7dkZOTY9znvffewwcffICFCxdi//790Gg0SExMNK654Un279+PJUuWoFmzZibbPT3G69evo2PHjlAqldi0aROOHz+OuXPnIiwszLiPJ8c4Z84cfPLJJ1i4cCFOnDiB9957D++//z4++ugj4z6eFl9OTg6aN2+OhQsXmn1eSjwTJkzAunXrsHr1avz222+4efMm+vTpg6KiosoKwyprMebm5uLQoUN46623cOjQIXz77bc4deoU+vXrZ7KfJ8dY0nfffYe9e/ciNja2zHPuHqNdBBm1bdtWPP/88ybbGjZsKCZPnuyiEjlPZmamACB27twphBBCr9cLjUYjZs+ebdwnLy9PhIaGik8++cRVxXRIdna2qF+/vkhOThadO3cW48ePF0J4R4yTJk0SnTp1svi8p8fYu3dv8dRTT5lsGzhwoBg6dKgQwvPjAyDWrVtnfCwlnhs3bgilUilWr15t3OfixYtCLpeLzZs3V1rZpSodozn79u0TAMT58+eFEN4T44ULF0T16tVFSkqKqFWrlpg3b57xOU+L0RbWLNxWUFCAgwcPonv37ibbu3fvjl27drmoVM6TlZUFAAgPDwcApKamIiMjwyRelUqFzp07e1y8Y8aMQe/evdGtWzeT7d4Q4/r169G6dWs8+uijiIqKwt13343PPvvM+Lynx9ipUyf8/PPPOHXqFADgjz/+wG+//YZevXoB8Pz4SpMSz8GDB6HT6Uz2iY2NRUJCgkfGDBT//shkMmONmDfEqNfrMWzYMLz66qto0qRJmee9IcaSPHohKWe6cuUKioqKEB0dbbI9OjoaGRkZLiqVcwghMHHiRHTq1AkJCQkAYIzJXLznz5+v9DI6avXq1Th06BD2799f5jlviPHs2bNYvHgxJk6ciClTpmDfvn148cUXoVKpMHz4cI+PcdKkScjKykLDhg2hUChQVFSEmTNnYtCgQQC84zMsSUo8GRkZ8Pf3R9WqVcvs44m/RXl5eZg8eTIGDx5sXGjJG2KcM2cO/Pz88OKLL5p93htiLInJQimll7oWQjht+WtXGTt2LP7880/89ttvZZ7z5HjT0tIwfvx4bNmyBWq12uJ+nhyjXq9H69at8e677wIA7r77bhw7dgyLFy/G8OHDjft5aoxr1qzBihUrsHLlSjRp0gRHjhzBhAkTEBsbixEjRhj389T4LHEkHk+MWafT4YknnoBer8eiRYts7u8pMR48eBALFizAoUOH7C6vp8RYGpshbouMjIRCoSiT8WVmZpa5C/Ak48aNw/r167F9+3aT5bw1Gg0AeHS8Bw8eRGZmJlq1agU/Pz/4+flh586d+PDDD+Hn52eMw5NjjImJQePGjU22NWrUyNjp1tM/x1dffRWTJ0/GE088gaZNm2LYsGF46aWXMGvWLACeH19pUuLRaDQoKCjA9evXLe7jCXQ6HR577DGkpqYiOTnZZPlmT4/x119/RWZmJmrWrGn87Tl//jxefvll1K5dG4Dnx1gak4Xb/P390apVKyQnJ5tsT05Oxj333OOiUjlOCIGxY8fi22+/xbZt2xAfH2/yfHx8PDQajUm8BQUF2Llzp8fE27VrVxw9ehRHjhwx/mvdujWGDBmCI0eOoE6dOh4fY8eOHcsMeT116hRq1aoFwPM/x9zcXMjlpj9DCoXCOHTS0+MrTUo8rVq1glKpNNknPT0dKSkpHhOzIVE4ffo0tm7dioiICJPnPT3GYcOG4c8//zT57YmNjcWrr76Kn376CYDnx1iGizpWuqXVq1cLpVIpli5dKo4fPy4mTJgggoKCxLlz51xdNLu98MILIjQ0VOzYsUOkp6cb/+Xm5hr3mT17tggNDRXffvutOHr0qBg0aJCIiYkRWq3WhSUvn5KjIYTw/Bj37dsn/Pz8xMyZM8Xp06fFf//7XxEYGChWrFhh3MeTYxwxYoSoXr26+OGHH0Rqaqr49ttvRWRkpHjttdeM+3hafNnZ2eLw4cPi8OHDAoD44IMPxOHDh40jAaTE8/zzz4saNWqIrVu3ikOHDokHHnhANG/eXBQWFroqLBPWYtTpdKJfv36iRo0a4siRIya/P/n5+cZjeHKM5pQeDSGE+8doDyYLpXz88ceiVq1awt/fX7Rs2dI41NDTADD7b9myZcZ99Hq9mDp1qtBoNEKlUon77rtPHD161HWFdoLSyYI3xLhhwwaRkJAgVCqVaNiwoViyZInJ854co1arFePHjxc1a9YUarVa1KlTR7zxxhsmFxVPi2/79u1m//ZGjBghhJAWz61bt8TYsWNFeHi4CAgIEH369BH//POPC6Ixz1qMqampFn9/tm/fbjyGJ8dojrlkwd1jtAeXqCYiIiKr2GeBiIiIrGKyQERERFYxWSAiIiKrmCwQERGRVUwWiIiIyComC0RERGQVkwUiIiKyiskCERERWcVkgYiIiKxiskDkI0aOHIkBAwZU6nsWFRVh1qxZaNiwIQICAhAeHo727dtj2bJlxn26dOmCCRMmVGq5iMg+fq4uABF5r6SkJCxZsgQLFy5E69atodVqceDAgTLL9hKRe2PNAhEBAHbu3Im2bdtCpVIhJiYGkydPRmFhofH57OxsDBkyBEFBQYiJicG8efNs1gps2LABo0ePxqOPPor4+Hg0b94co0aNwsSJEwEU13bs3LkTCxYsgEwmg0wmw7lz5wAAx48fR69evVClShVER0dj2LBhuHLlivHYXbp0wdixYzF27FiEhYUhIiICb775JrjcDZHzMVkgIly8eBG9evVCmzZt8Mcff2Dx4sVYunQpZsyYYdxn4sSJ+P3337F+/XokJyfj119/xaFDh6weV6PRYNu2bfj333/NPr9gwQJ06NABzzzzDNLT05Geno64uDikp6ejc+fOaNGiBQ4cOIDNmzfj8uXLeOyxx0xe/+WXX8LPzw979+7Fhx9+iHnz5uHzzz8v/wkhIlMuXvWSiCrJiBEjRP/+/c0+N2XKFNGgQQOh1+uN2z7++GNRpUoVUVRUJLRarVAqleKbb74xPn/jxg0RGBhosiR4aceOHRONGjUScrlcNG3aVDz33HNi48aNJvuUXlZcCCHeeust0b17d5NtaWlpAoA4efKk8XWNGjUyKfOkSZNEo0aNrJ0GInIAaxaICCdOnECHDh0gk8mM2zp27IibN2/iwoULOHv2LHQ6Hdq2bWt8PjQ0FA0aNLB63MaNGyMlJQV79uzBk08+icuXL6Nv3754+umnrb7u4MGD2L59O6pUqWL817BhQwDAmTNnjPu1b9/epMwdOnTA6dOnUVRUZFf8RGQdOzgSEYQQJhddwzYAkMlkJv9vbh9r5HI52rRpgzZt2uCll17CihUrMGzYMLzxxhuIj483+xq9Xo++fftizpw5ZZ6LiYmRFBMROQ+TBSJC48aNsXbtWpOkYdeuXQgODkb16tURFhYGpVKJffv2IS4uDgCg1Wpx+vRpdO7c2e73AoCcnBwAgL+/f5magJYtW2Lt2rWoXbs2/Pws/0zt2bOnzOP69etDoVDYVSYiso7NEEQ+JCsrC0eOHDH5988//2D06NFIS0vDuHHj8Ndff+H777/H1KlTMXHiRMjlcgQHB2PEiBF49dVXsX37dhw7dgxPPfUU5HJ5mdqGkh555BHMmzcPe/fuxfnz57Fjxw6MGTMGd911l7FZoXbt2ti7dy/OnTuHK1euQK/XY8yYMbh27RoGDRqEffv24ezZs9iyZQueeuopk8QiLS0NEydOxMmTJ7Fq1Sp89NFHGD9+fIWfRyKf49IeE0RUaUaMGCEAlPk3YsQIIYQQO3bsEG3atBH+/v5Co9GISZMmCZ1OZ3y9VqsVgwcPFoGBgUKj0YgPPvhAtG3bVkyePNniey5ZskTcf//9olq1asLf31/UrFlTjBw5Upw7d864z8mTJ0X79u1FQECAACBSU1OFEEKcOnVKPPTQQyIsLEwEBASIhg0bigkTJhg7NHbu3FmMHj1aPP/88yIkJERUrVpVTJ482aTDIxE5h0wIDkomIvvl5OSgevXqmDt3LkaNGlXp79+lSxe0aNEC8+fPr/T3JvI17LNARJIcPnwYf/31F9q2bYusrCxMnz4dANC/f38Xl4yIKhqTBSKS7D//+Q9OnjwJf39/tGrVCr/++isiIyNdXSwiqmBshiAiIiKrOBqCiIiIrGKyQERERFYxWSAiIiKrmCwQERGRVUwWiIiIyComC0RERGQVkwUiIiKyiskCERERWfX/qvw6wWxHJgYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "loss_history = [log[\"loss\"] for log in trainer.state.log_history if \"loss\" in log]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(len(loss_history)), loss_history, marker='o', label=\"Training Loss\")\n",
    "plt.xlabel(\"Log Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss during SFT Training\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u27e41mf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract training and evaluation perplexity\n",
    "train_perplexity = [log.get(\"train_perplexity\") for log in trainer.state.log_history if \"train_perplexity\" in log]\n",
    "eval_perplexity = [log.get(\"eval_perplexity\") for log in trainer.state.log_history if \"eval_perplexity\" in log]\n",
    "eval_steps = [log[\"step\"] for log in trainer.state.log_history if \"eval_perplexity\" in log]\n",
    "\n",
    "# Plot perplexity\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Training perplexity over time\n",
    "ax1.plot(range(len(train_perplexity)), train_perplexity, marker='o', label=\"Training Perplexity\", alpha=0.7)\n",
    "ax1.set_xlabel(\"Log Step\")\n",
    "ax1.set_ylabel(\"Perplexity\")\n",
    "ax1.set_title(\"Training Perplexity\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot 2: Training vs Evaluation perplexity\n",
    "ax2.plot(range(len(train_perplexity)), train_perplexity, label=\"Train Perplexity\", alpha=0.7)\n",
    "if eval_perplexity:\n",
    "    # Map eval steps to train step indices for alignment\n",
    "    train_steps = [log[\"step\"] for log in trainer.state.log_history if \"train_perplexity\" in log]\n",
    "    eval_step_indices = [train_steps.index(step) if step in train_steps else None for step in eval_steps]\n",
    "    eval_step_indices = [i for i in eval_step_indices if i is not None]\n",
    "    eval_perplexity_filtered = [eval_perplexity[i] for i in range(len(eval_step_indices))]\n",
    "    ax2.plot(eval_step_indices, eval_perplexity_filtered, label=\"Eval Perplexity\", marker='o', color='orange')\n",
    "ax2.set_xlabel(\"Log Step\")\n",
    "ax2.set_ylabel(\"Perplexity\")\n",
    "ax2.set_title(\"Training vs Evaluation Perplexity\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "if train_perplexity:\n",
    "    print(f\"\\nFinal Training Perplexity: {train_perplexity[-1]:.4f}\")\n",
    "if eval_perplexity:\n",
    "    print(f\"Final Evaluation Perplexity: {eval_perplexity[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2585e",
   "metadata": {},
   "source": [
    "### Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"How are you?\"\n",
    "messages = [{\"role\": \"user\", \"content\": content}]\n",
    "prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30b86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: I'm just a virtual assistant, but I'm here to help! How can I assist you?\n"
     ]
    }
   ],
   "source": [
    "output_ids = model.generate(**inputs, max_new_tokens=50)\n",
    "baseline_answer = tokenizer.decode(output_ids[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "print(f'Model output: {baseline_answer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631af76e",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0acb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
